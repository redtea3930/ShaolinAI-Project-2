{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b80b3cc5-603d-4724-9179-b1f762a2e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pathlib import Path\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "606c2cda-48a1-4431-be34-c839cf1cd02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in cleaned CSV\n",
    "filepath = Path('massive.csv')\n",
    "massive = pd.read_csv(filepath)\n",
    "massive = massive.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8ef3920-1a56-4063-8460-b6be9b18ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to process text on the data\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import re\n",
    "def process_text(text): \n",
    "    sw = set(stopwords.words('english')) \n",
    "    regex = re.compile(\"[^a-zA-Z ]\") \n",
    "    re_clean = regex.sub('', text) \n",
    "    words = word_tokenize(re_clean) \n",
    "    lem = [lemmatizer.lemmatize(word) for word in words] \n",
    "    output = ' '.join([word.lower() for word in lem if word.lower() not in sw]) \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dde6990b-5398-4f51-b517-502d386a59f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a lambda x function to apple process text on the whole column.\n",
    "massive['reviewText'] = massive['reviewText'].apply(lambda x: process_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c499634-2bfb-41f7-966a-a8877201f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = tfidf_vectorizer.fit_transform(massive['reviewText'])\n",
    "y = massive['scoreSentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "698b1ab1-8b50-4058-a10e-bc4988f21785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Choose a machine learning model (e.g., Logistic Regression) and train it\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "253355ed-d047-4679-8c24-99252f8f734a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.744"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93b1bd7a-d373-4ddb-977b-3fcb97f7f85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.692"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "326e26c0-c76a-4826-be13-79c35472cfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Athen\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "massive_features = pd.DataFrame(X.toarray(), columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8d2db-9d4f-4494-8b24-43620e7698ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "35a70089-6243-40b4-b7a7-b5bfce444c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([massive, massive_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66941dde-e810-4c38-b202-daed024aa859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>audienceScore</th>\n",
       "      <th>tomatoMeter</th>\n",
       "      <th>reviewId</th>\n",
       "      <th>creationDate</th>\n",
       "      <th>criticName</th>\n",
       "      <th>isTopCritic</th>\n",
       "      <th>reviewState</th>\n",
       "      <th>publicatioName</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>youd</th>\n",
       "      <th>youll</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139125</th>\n",
       "      <td>vaxxed_from_cover_up_to_catastrophe_2016</td>\n",
       "      <td>Vaxxed: From Cover-Up to Catastrophe</td>\n",
       "      <td>84.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2324052.0</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>Mick LaSalle</td>\n",
       "      <td>True</td>\n",
       "      <td>fresh</td>\n",
       "      <td>San Francisco Chronicle</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520634</th>\n",
       "      <td>harts_war</td>\n",
       "      <td>Hart's War</td>\n",
       "      <td>48.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>809945.0</td>\n",
       "      <td>2002-11-07</td>\n",
       "      <td>James Rocchi</td>\n",
       "      <td>False</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548346</th>\n",
       "      <td>million_dollar_arm</td>\n",
       "      <td>Million Dollar Arm</td>\n",
       "      <td>68.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2203414.0</td>\n",
       "      <td>2014-05-16</td>\n",
       "      <td>Travis Hopson</td>\n",
       "      <td>False</td>\n",
       "      <td>rotten</td>\n",
       "      <td>Examiner.com</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227293</th>\n",
       "      <td>there_will_be_blood</td>\n",
       "      <td>There Will Be Blood</td>\n",
       "      <td>86.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1692485.0</td>\n",
       "      <td>2007-11-28</td>\n",
       "      <td>Joshua Tyler</td>\n",
       "      <td>False</td>\n",
       "      <td>fresh</td>\n",
       "      <td>CinemaBlend</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97683</th>\n",
       "      <td>hobo_with_a_shotgun</td>\n",
       "      <td>Hobo With a Shotgun</td>\n",
       "      <td>57.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1988815.0</td>\n",
       "      <td>2011-05-30</td>\n",
       "      <td>Kelly Vance</td>\n",
       "      <td>False</td>\n",
       "      <td>fresh</td>\n",
       "      <td>East Bay Express</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1012 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              id  \\\n",
       "139125  vaxxed_from_cover_up_to_catastrophe_2016   \n",
       "520634                                 harts_war   \n",
       "548346                        million_dollar_arm   \n",
       "227293                       there_will_be_blood   \n",
       "97683                        hobo_with_a_shotgun   \n",
       "\n",
       "                                       title  audienceScore  tomatoMeter  \\\n",
       "139125  Vaxxed: From Cover-Up to Catastrophe           84.0         38.0   \n",
       "520634                            Hart's War           48.0         60.0   \n",
       "548346                    Million Dollar Arm           68.0         64.0   \n",
       "227293                   There Will Be Blood           86.0         91.0   \n",
       "97683                    Hobo With a Shotgun           57.0         66.0   \n",
       "\n",
       "         reviewId creationDate     criticName isTopCritic reviewState  \\\n",
       "139125  2324052.0   2016-04-29   Mick LaSalle        True       fresh   \n",
       "520634   809945.0   2002-11-07   James Rocchi       False       fresh   \n",
       "548346  2203414.0   2014-05-16  Travis Hopson       False      rotten   \n",
       "227293  1692485.0   2007-11-28   Joshua Tyler       False       fresh   \n",
       "97683   1988815.0   2011-05-30    Kelly Vance       False       fresh   \n",
       "\n",
       "                 publicatioName  ... year yes  yet  york  youd  youll  young  \\\n",
       "139125  San Francisco Chronicle  ...  NaN NaN  NaN   NaN   NaN    NaN    NaN   \n",
       "520634                  Netflix  ...  NaN NaN  NaN   NaN   NaN    NaN    NaN   \n",
       "548346             Examiner.com  ...  NaN NaN  NaN   NaN   NaN    NaN    NaN   \n",
       "227293              CinemaBlend  ...  NaN NaN  NaN   NaN   NaN    NaN    NaN   \n",
       "97683          East Bay Express  ...  NaN NaN  NaN   NaN   NaN    NaN    NaN   \n",
       "\n",
       "        younger  youre  youve  \n",
       "139125      NaN    NaN    NaN  \n",
       "520634      NaN    NaN    NaN  \n",
       "548346      NaN    NaN    NaN  \n",
       "227293      NaN    NaN    NaN  \n",
       "97683       NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 1012 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67906b7c-4a85-4a51-bfc0-bfe943a195b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
